{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e10a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ECGs for the main project\n",
    "distdr_medians = np.load('DISTDR_medians_precprocessed.npy')\n",
    "\n",
    "#Crop these as well, get the exterimities\n",
    "distdr_medians_cropped = distdr_medians[:, :6, 20:-20]\n",
    "distdr_medians_cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f461245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "input_signal = Input(shape=(6, 210,))\n",
    "latent_dim = 16\n",
    "\n",
    "# Encoder layers\n",
    "x = Flatten()(input_signal)\n",
    "x = Dense(128, activation='relu', trainable=True)(x)\n",
    "x = Dense(64, activation='relu', trainable=True)(x)\n",
    "\n",
    "# Define mean and log-variance layers for latent variables\n",
    "z_mean = Dense(latent_dim, trainable=True)(x)\n",
    "z_log_var = Dense(latent_dim, trainable=True)(x)\n",
    "\n",
    "# Define sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder layers\n",
    "x = Dense(64, activation='relu', trainable=True)(z)\n",
    "x = Dense(128, activation='relu', trainable=True)(x)\n",
    "decoded = Dense(6 * 210, activation='sigmoid', trainable=True)(x)\n",
    "decoded = Reshape((6, 210))(decoded)\n",
    "\n",
    "\n",
    "vae_model = Model(input_signal, decoded)\n",
    "\n",
    "vae_model.load_weights('pretrained_autoencoder_weights.h5')\n",
    "\n",
    "# Define VAE loss function\n",
    "beta = 1\n",
    "def vae_loss(input_signal, decoded):\n",
    "    mse_loss = K.mean(K.square(input_signal - decoded), axis=(1,2))\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return mse_loss + beta * kl_loss\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "vae_model.compile(optimizer=adam, loss=vae_loss)\n",
    "\n",
    "# Define encoder model\n",
    "encoder_model = Model(input_signal, z_mean)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=2,\n",
    "                               verbose=1,\n",
    "                               mode='min')\n",
    "\n",
    "# Train the VAE model\n",
    "history = vae_model.fit(distdr_medians_cropped, distdr_medians_cropped,\n",
    "                        epochs=128,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True,\n",
    "                        validation_split=0.15,\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "# Reconstruct input signal\n",
    "reconstructed_signal = vae_model.predict(distdr_medians_cropped)\n",
    "\n",
    "indices = np.random.choice(distdr_medians_cropped.shape[0], 77099, replace=False)\n",
    "pearson_all = list()\n",
    "for i, idx in enumerate(indices):\n",
    "        for j in range(1, 6):\n",
    "            correlation_matrix = np.corrcoef(distdr_medians_cropped[i, j], reconstructed_signal[i, j], rowvar=False)\n",
    "            pearson_correlation = correlation_matrix[0, 1]\n",
    "            pearson_all.append(pearson_correlation)\n",
    "print(\"Pearson mean\", np.mean(pearson_all))\n",
    "print(\"Pearson std\", np.std(pearson_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24c192",
   "metadata": {},
   "source": [
    "# Calculate metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays to store RMSE and PRD values\n",
    "rmse_all = []\n",
    "prd_all = []\n",
    "\n",
    "# Iterate over each sample\n",
    "for i, idx in enumerate(range(len(distdr_medians_cropped))):\n",
    "    for j in range(1, 6):\n",
    "        # Min-max normalization on the original and reconstructed signals\n",
    "        original_signal_normalized = (distdr_medians_cropped[idx, j] - np.min(distdr_medians_cropped[idx, j])) / (np.max(distdr_medians_cropped[idx, j]) - np.min(distdr_medians_cropped[idx, j]))\n",
    "        reconstructed_signal_normalized = (reconstructed_signal[idx, j] - np.min(reconstructed_signal[idx, j])) / (np.max(reconstructed_signal[idx, j]) - np.min(reconstructed_signal[idx, j]))\n",
    "\n",
    "        # Calculate RMSE\n",
    "        mse = np.mean((original_signal_normalized - reconstructed_signal_normalized) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        rmse_all.append(rmse)\n",
    "\n",
    "        # Calculate PRD\n",
    "        numerator = np.sum((original_signal_normalized - reconstructed_signal_normalized) ** 2)\n",
    "        denominator = np.sum(original_signal_normalized ** 2)\n",
    "        prd = 100 * np.sqrt(numerator / denominator)\n",
    "        prd_all.append(prd)\n",
    "\n",
    "# Calculate and print RMSE and PRD statistics\n",
    "rmse_mean = np.mean(rmse_all)\n",
    "rmse_std = np.std(rmse_all)\n",
    "\n",
    "prd_mean = np.mean(prd_all)\n",
    "prd_std = np.std(prd_all)\n",
    "\n",
    "print(\"RMSE mean:\", rmse_mean)\n",
    "print(\"RMSE std:\", rmse_std)\n",
    "\n",
    "print(\"PRD mean:\", prd_mean)\n",
    "print(\"PRD std:\", prd_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "\n",
    "# Reconstruct input signal\n",
    "reconstructed_signal = vae_model.predict(distdr_medians_cropped)\n",
    "\n",
    "# Create an array to store DTW distances\n",
    "dtw_distances = []\n",
    "\n",
    "# Iterate over each sample\n",
    "for i, idx in enumerate(range(len(distdr_medians_cropped))):\n",
    "    for j in range(1, 6):\n",
    "        # Calculate DTW distance\n",
    "        dist, _ = fastdtw(distdr_medians_cropped[idx, j], reconstructed_signal[idx, j])\n",
    "        dtw_distances.append(dist)\n",
    "\n",
    "# Calculate and print DTW statistics\n",
    "dtw_mean = np.mean(dtw_distances)\n",
    "dtw_std = np.std(dtw_distances)\n",
    "\n",
    "print(\"DTW mean:\", dtw_mean)\n",
    "print(\"DTW std:\", dtw_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f046040",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder_model.predict(distdr_medians_cropped)\n",
    "encoded_imgs_df = pd.DataFrame(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f292b6",
   "metadata": {},
   "source": [
    "# Reconstructions versus original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(16, 10))\n",
    "\n",
    "# Generate random case index\n",
    "case_idx = np.random.randint(len(distdr_medians_cropped))\n",
    "titles = ['I', 'II', 'III', 'aVR', 'avL', 'avF']\n",
    "\n",
    "time_axis = np.linspace(0, 1, num=len(distdr_medians_cropped[case_idx, 0, :]))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(time_axis, distdr_medians_cropped[case_idx, i, :], linestyle='-', linewidth = 3.5, color='darkblue', alpha=0.65)\n",
    "    ax.grid(linewidth=0.5, color='gray', linestyle='--')\n",
    "    ax.set_title(f'{titles[i]}')\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.plot(time_axis, reconstructed_signal[case_idx, i, :], linestyle='-', color='darkorange',linewidth = 3.5, alpha=0.65)\n",
    "    ax.grid(linewidth=0.5, color='gray', linestyle='--')\n",
    "    ax.set_title(f'{titles[i]}')\n",
    "    \n",
    "correlation_matrix = np.corrcoef(reconstructed_signal[case_idx, i, :], distdr_medians_cropped[case_idx, i, :], rowvar=False)\n",
    "pearson_correlation = correlation_matrix[0, 1]\n",
    "print(\"Pearson mean:\", pearson_correlation)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
